<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xudong Yu</title>
  
  <meta name="author" content="Xudong Yu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xudong Yu</name>
              </p>
              <p><font size="3">I am a PhD student at the School of Astronautics, Harbin Institute of Technology.</font>
              </p>
              <p>
                <font size="3">
				I received my Bachelor‚Äôs degree and Master‚Äôs degree from HIT. I‚Äôm now doing research about offline reinforcement learning, online adaptation, and generalization on environmental dynamics and rewards. Recently, I also pay attention to Preference based Reinforcement Learning (PbRL) and Reinforcement Learning from Human Feedback (RLHF). 
              </font>
                </p>
                <p>
              <font size="3">
        I hope the agent can leverage amounts of offline data and adapt to new environments smoothly without discarding previous knowledge. Considering the applications in practical, interction with human is indispensible. In that case, I hope agents can adjust their behaviors following human's preference, instead of carefully designed reward functions.
                </font>
              </p>
              <p>
            <font size="3">
    I also care about foundation models for decision making, embodied AI, and recent advances in LLM.
			    </font>
			  </p>
              <p style="text-align:center">
                <a href="hit20byu@gmail.com"><font size="3">Email</font></a> &nbsp/&nbsp
                <a href="data/yuxudong-hit.pdf"><font size="3">CV</font></a> &nbsp/&nbsp
                <a href="data/yuxudong-bio.txt"><font size="3">Bio</font></a> &nbsp/&nbsp
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=nPd9WqUAAAAJ"><font size="3">Google Scholar</font></a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/sincerely-43"><font size="3">Zhihu</font></a> &nbsp/&nbsp
                <a href="https://github.com/yuxudong20"><font size="3">Github</font></a>
              </p>
            </td>
            <td style="width:25%;max-width:30%">
              <a href="images/XudongYu.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/XudongYu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
			    <font size="3">
                I'm interested in offline RL, offline-to-online RL, generalization, and etc.
                </font>
			  </p>
            </td>
          </tr>
        </tbody></table>
		
        <table style='border-spacing:0px;border-collapse:collapse;'><tbody>
          <tr>
            <td style="width:25%;vertical-align:top">
              <div class="one" id='esr_image'>
                  <img src='images/esr.png' width="160" height='120'>
              </div>
            </td>
            <td style="width:75%;vertical-align:top">
			  <font size="3">
			  <strong><font size="3">Ensemble Successor Representations for Task Generalization in Offline-to-Online Reinforcement Learning.</font></strong>
              <br>
              Changhong Wang, <strong><font size="3">Xudong Yu*</font></strong>, Chenjia Bai, Zhen Wang
              <br>
              <em>Under Review</em>
              <br>
				<!-- <a href="https://ieeexplore.ieee.org/document/10221854">paper</a> -->
			  <p></p-->
			  </font>
			  </font>
            </td>
          </tr>
          <tr>
            <td style="width:25%;vertical-align:top">
              <div class="one" id='burl_image'>
                  <img src='images/burl.png' width="160" height='120'>
              </div>
            </td>
            <td style="width:75%;vertical-align:top">
			  <font size="3">
			  <strong><font size="3">Lightweight Uncertainty for Offline Reinforcement Learning via Bayesian Posterior.</font></strong>
              <br>
			  <strong><font size="3">Xudong Yu</font></strong>, Chenjia Bai, Changhong Wang, Zhen Wang, Xuelong Li
              <br>
              <em>Under Review</em>
              <br>
				<!-- <a href="https://ieeexplore.ieee.org/document/10221854">paper</a> -->
			  <p></p-->
			  </font>
			  </font>
            </td>
          </tr>
		  <tr>
            <td style="width:25%;vertical-align:top">
              <div class="one" id='hss_image'>
                  <img src='images/hss.png' width="160" height='120'>
              </div>
            </td>
            <td style="width:75%;vertical-align:top">
			  <font size="3">
			  <strong><font size="3">Self-Supervised Imitation for Offline Reinforcement Learning With Hindsight Relabeling.</font></strong>
              <br>
			  <strong><font size="3">Xudong Yu</font></strong>, Chenjia Bai, Changhong Wang, Dengxiu Yu, C.L. Philip Chen, Zhen Wang
              <br>
              <em>IEEE Transactions on Systems, Man, Cybernetics: Systems, 2023</em>
              <br>
				<a href="https://ieeexplore.ieee.org/document/10221854">paper</a>
			  <p></p-->
			  </font>
			  </font>
            </td>
          </tr>
		  <tr>
            <td style="width:25%;vertical-align:top">
              <div class="one" id='cgi_image'>
                  <img src='images/cgi.png' width="160" height='150'>
              </div>
            </td>
            <td style="width:75%;vertical-align:top">
			  <strong><font size="3">Curriculum Goal-conditioned Self-imitation for Offline Reinforcement Learning.</font></strong>
              <br>
			  <font size="3">Xiaoyun Feng, Li Jiang, <strong><font size="3">Xudong Yu</font></strong>,
			  Haoran Xu, Xiaoyan Sun, Jie Wang, Xianyuan Zhan, Wai Kin (Victor) Chan
              <br>
              <em>IEEE Transactions on Games</em>, 2022
              <a href="https://ieeexplore.ieee.org/abstract/document/9962804">paper</a>
              <p>
              </p>
            </td>
          </tr>
					
          <tr>
            <td style="width:25%;vertical-align:top">
              <div class="one" id='icus_image'>
                  <img src='images/icus.jpg' width="160" height='100'>
              </div>
            </td>
            <td style="width:75%;vertical-align:top">
			  <strong><font size="3">Multi-Sensor Fusion Localization with Factor Graphs for UGVs Under Adverse Conditions.</font></strong>
              <br>
			  <font size="3">
			  <strong><font size="3">Xudong Yu</font></strong>, Changhong Wang
              <br>
              <em>IEEE International Conference on Unmanned Systems (ICUS)</em>, 2021</font>
			  <br>
				<a href="https://ieeexplore.ieee.org/abstract/document/9641425"><font size="3">paper</font></a>
            </td>
          </tr>
		  
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
